{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Predicting Risks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am interested in finding the best model. But first, I will use default settings. Then, I will use a random grid search to fine tune parameters. Then grid search to narrow down the paramerters I should use. Finally, I will compare this best model to the one produced by the default settings. I am going to try **logistic regression** and **random forest**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # to measure within momdel acuracy\n",
    "from sklearn.preprocessing import StandardScaler # need to scale data for logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import osmnx\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "robbery_model_data_dummies_bal = pandas.read_pickle('C:/Users/jodyn/Google Drive/Insight/Processed Data/robbery_model_data_dummies_bal.pkl.pkl')\n",
    "pedestrian_model_data_dummies_bal = pandas.read_pickle('C:/Users/jodyn/Google Drive/Insight/Processed Data/pedestrian_model_data_dummies_bal.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "robbery_labels = robbery_model_data_dummies_bal['Presence_Absence']\n",
    "robbery_features = robbery_model_data_dummies_bal.iloc[:, numpy.r_[1:4, 9:15]]\n",
    "robbery_model_names = list(robbery_model_data_dummies_bal.iloc[:, numpy.r_[1:4, 9:15]])\n",
    "\n",
    "pedestrian_labels = pedestrian_model_data_dummies_bal['Presence_Absence']\n",
    "pedestrian_features = pedestrian_model_data_dummies_bal.iloc[:, numpy.r_[0:1, 5:10,12:len(list(pedestrian_model_data_dummies_bal))]]\n",
    "pedestrian_features_names = list(pedestrian_model_data_dummies_bal.iloc[:, numpy.r_[0:1, 5:10,12:len(list(pedestrian_model_data_dummies_bal))]])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "robbery_train, robbery_test, robbery_presence_train, robbery_presence_test = train_test_split(\n",
    "    robbery_features,\n",
    "    robbery_labels, test_size=0.3, random_state=42)\n",
    "pedestrian_train, pedestrian_test, pedestrian_presence_train, pedestrian_presence_test = train_test_split(\n",
    "    pedestrian_features,pedestrian_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale data for logistic regression\n",
    "scaler = StandardScaler()\n",
    "robbery_train_lr = pandas.DataFrame(scaler.fit_transform(robbery_train),\n",
    "                                   columns=robbery_model_names)\n",
    "\n",
    "robbery_test_lr = pandas.DataFrame(scaler.fit_transform(robbery_test),\n",
    "                                  columns=robbery_model_names)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pedestrian_train_lr = pandas.DataFrame(scaler.fit_transform(pedestrian_train),\n",
    "                                   columns=pedestrian_features_names)\n",
    "\n",
    "pedestrian_test_lr = pandas.DataFrame(scaler.fit_transform(pedestrian_test),\n",
    "                                  columns=pedestrian_features_names)\n",
    "\n",
    "# Time to build the base model\n",
    "robbery_model_LR = LogisticRegression()\n",
    "robbery_model_LR.fit(robbery_train_lr, robbery_presence_train_lr)\n",
    "robbery_model_prediction_LR = robbery_model_LR.predict(robbery_test_lr)\n",
    "\n",
    "pedestrian_model_LR = LogisticRegression()\n",
    "pedestrian_model_LR.fit(pedestrian_train_lr, pedestrian_presence_train_lr)\n",
    "pedestrian_model_prediction_LR = pedestrian_model_LR.predict(pedestrian_test_lr)\n",
    "\n",
    "# how did these models perform?\n",
    "print(classification_report(robbery_presence_test, robbery_model_prediction_LR))\n",
    "print(classification_report(pedestrian_presence_test, pedestrian_model_prediction_LR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Path Data - OSMNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_path_GTA = osmnx.graph_from_place(place_name, network_type='walk')\n",
    "\n",
    "# need to reproject to UTM for later analysis\n",
    "walk_path_GTA_proj = osmnx.project_graph(walk_path_GTA)\n",
    "\n",
    "# need edges and nodes to append data to\n",
    "walk_nodes_proj, walk_edges_proj = osmnx.graph_to_gdfs(walk_path_GTA, nodes=True, edges=True)\n",
    "\n",
    "# making sure its in NAD 1983 and save\n",
    "walk_nodes_proj = walk_nodes_proj.to_crs(epsg = 2958)\n",
    "\n",
    "walk_nodes_proj['Index'] = walk_nodes_proj.index\n",
    "\n",
    "# converting the node data to a geopanda dataframe so that I can extract elevation data\n",
    "walk_node_id = pandas.DataFrame(walk_nodes_proj)\n",
    "walk_nodes_gdf = create_gdf(df=walk_node_id,\n",
    "                            Latitude=\"y\",\n",
    "                            Longitude=\"x\",\n",
    "                            projection=\"EPSG:4326\")\n",
    "walk_nodes_gdf = walk_nodes_gdf.to_crs(epsg=2958)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Terrain Data - Government of Canada\n",
    "Need to pull in the terrain data so that I can add them to the road network nodes and then to the edges as weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal # dealing with raster data\n",
    "\n",
    "filepath_TSC = r\"C:/Users/jodyn/Google Drive/Insight/Terrain/TSC_2958.tif\"\n",
    "filepath_Hillshade = r\"C:/Users/jodyn/Google Drive/Insight/Terrain/Hillshade_2958.tif\"\n",
    "raster_TSC = gdal.Open(filepath_TSC)\n",
    "raster_Hillshade = gdal.Open(filepath_Hillshade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use IDW to interpolate the probabilty values at each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need path in wgs\n",
    "walk_nodes_gdf = walk_nodes_gdf.to_crs(epsg = 4326)\n",
    "# saving as something else so that I can add to my main dataframe\n",
    "walk_nodes_gdf_NB = nearest_neighbor_2(walk_nodes_gdf, robbery_model_nodes_4326,\n",
    "                                             return_dist=True)\n",
    "walk_nodes_gdf_NB_pd = nearest_neighbor_2(walk_nodes_gdf, pedestrian_model_nodes_4326,\n",
    "                                             return_dist=True)\n",
    "# adding index for future join to full node dataset\n",
    "walk_nodes_gdf_NB.set_index(walk_nodes_gdf.index,inplace = True)\n",
    "walk_nodes_gdf_NB_pd.set_index(walk_nodes_gdf.index,inplace = True)\n",
    "# also adding model outputs at each nodes for edge weights later\n",
    "walk_nodes_gdf_NB['TSC'] = list(walk_nodes_gdf['TSC'])\n",
    "walk_nodes_gdf_NB['Hillshade'] = list(walk_nodes_gdf['Hillshade'])\n",
    "walk_nodes_gdf_NB['Collison'] = list(walk_nodes_gdf_NB_pd['Collison'])\n",
    "walk_nodes_gdf_NB['No_Collison'] = list(walk_nodes_gdf_NB_pd['No_Collison'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Node & Edge Data for Shortest Path in Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "walk_nodes_gdf_NB.to_pickle(\"data/cleaned/walknodes.pkl\")\n",
    "walk_edges_proj.to_pickle(\"data/cleaned/edges.pkl\")\n",
    "walk_nodes_proj.to_pickle(\"data/cleaned/nodes.pkl\")\n",
    "with open(\"data/cleaned/path.p\", 'wb') as f:\n",
    "    pickle.dump(walk_path_GTA_proj,f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
